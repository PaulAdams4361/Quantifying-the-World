---
title: "Spam Message Detection"
author: "Stuart Miller, Justin Howard, and Paul Adams"
date: October 6, 2020
lang: en-US
class: man
# figsintext: true
numbersections: true
encoding: UTF-8
# bibliography: references.bib
# biblio-style: apalike
output:
  bookdown::pdf_document2:
     citation_package: natbib
     keep_tex: false
     toc: false
header-includes:
   - \usepackage{amsmath}
   - \usepackage{gensymb}
   - \usepackage[utf8]{inputenc}
   - \usepackage[T1]{fontenc}
   - \usepackage{setspace}
   - \usepackage{hyperref}
   - \onehalfspacing
   - \newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
editor_options: 
  chunk_output_type: console
---

```{r}
install.packages("tm")
library("tm")
```


```{r, read_data, include=FALSE}
# video 1

# list the data diectories
list.dirs('./data/', full.names = F)

# get the number of data directories
length(list.files(paste('./data/', sep=.Platform$file.sep)))

# get all the data directory names
dir.names <- list.files(paste('./data', sep=.Platform$file.sep))

# list the number of files in each data directory
sapply(paste('./data', dir.names, sep = .Platform$file.sep), 
       function(dir) length(list.files(dir)))

# get the full data dir names
filldirNames <- paste('./data', dir.names, sep = .Platform$file.sep)

# list full dir names of data files; print sample
fileNames <- list.files(filldirNames[1], full.names = T)
fileNames[1]

# get some example enail files from the first dir
messageIdx <- c(1:5, 15, 27, 68, 69, 329, 404, 427, 516, 852, 971)
fn = list.files(filldirNames[1], full.names = T)[messageIdx]
sampleEmail <- sapply(fn, readLines)
sampleEmail
```


```{r, splitting, include=F}
# video 2

# get a sample email to work with
msg <- sampleEmail[[1]]

# get the blank line as a split point
which(msg == '')[1]
match('', msg)

# save the split point for example message
splitPoint <- match('', msg)

# view area around split point
msg[ (splitPoint - 2) : (splitPoint + 6) ]

# get the header and body of teh example message
header <- msg[1 : (splitPoint - 1)]
body <- msg[ -( 1:(splitPoint - 1) ) ]

# create a function to split messages on the first empty line
# header is the first element and body is the second element
# of the split
splitMessage <- function(msg){
  splitPoint <- match('', msg)
  header <- msg[1 : (splitPoint - 1)]
  body <- msg[ -( 1:(splitPoint - 1) ) ]
  return(list(header = header, body = body))
}

# apply function to the sample messages
sampleSplit <- lapply(sampleEmail, splitMessage)
length(sampleSplit)

# pring the sample header
sampleSplit[[6]]$header

```


```{r, removing_attachments, include=F}
# video 3

# get some files and split them as before
messageIdx <- c(1:5, 15, 27, 68, 69, 329, 404, 427, 516, 852, 971,
                1070, 1267, 1450, 1585, 1709, 1234, 1046, 1149,
                1641, 1406)
fn = list.files(filldirNames[1], full.names = T)[messageIdx]
sampleEmail <- sapply(fn, readLines)
sampleSplit <- lapply(sampleEmail, splitMessage)

header <- sampleSplit[[1]]$header
grep("Content-Type", header)

# find locations of "Contenct-Type" (where the attachment is)
headerList <- lapply(sampleSplit, function(msg) msg$header)
CTloc <- sapply(headerList, grep, pattern = "Content-Type")
CTloc

# improvement where NA is returned for 0 (no occurance)
sapply(headerList, function(header){
  CTloc <- grep("Content-Type", header)
  if (length(CTloc) == 0) return (NA)
  CTloc
})

# find locations of attachements
hasAttach <- sapply(headerList, function(header){
  CTloc <- grep("Content-Type", header)
  if (length(CTloc) == 0) return (FALSE)
  grepl('multi', tolower(header[CTloc]))
})


header <- sampleSplit[[12]]$header
boundaryIdx <- grep('boundary=', header)
header[boundaryIdx]

sub(".*boundary=\"? *(.*)\"?;?.*", "\\1", header[boundaryIdx])

# a function to find boundaries
getBoundry <- function(header){
  boundaryIdx <- grep('boundary=', header)
  boundary = gsub('"', "", header[boundaryIdx])
  gsub(".*boundary= *([^;]*);?.*", "\\1", boundary)
}

# sample message with a PGP signature
sampleSplit[[12]]$body



```

































