---
title: "Modeling Runners' Times in the Cherry Blossom Race"
author: "Justin Howard, Stuart Miller, Paul Adams"
date: "September 22, 2020"
lang: en-US
class: man
# figsintext: true
numbersections: true
encoding: UTF-8
output:
  bookdown::pdf_document2:
     citation_package: natbib
     keep_tex: true
     toc: false
header-includes:
   - \usepackage{amsmath}
   - \usepackage{gensymb}
   - \usepackage[utf8]{inputenc}
   - \usepackage[T1]{fontenc}
   - \usepackage{setspace}
   - \usepackage{hyperref}
   - \onehalfspacing
editor_options: 
  chunk_output_type: console
---

# Introduction

The internet is a vast open resource for data, but internet data can be messy and difficult to wrangle. In this case study we collect data on participates of the Cherry Blossom Race from the Cherry Blossom Race website\footnotemark.
We find that there are a number of issues present in the data, including inconssitent web addressing formatting, inconsistent formatting, and missing data. We collect and clean this data to provide the Men's and Women's information in a format suitable for analysis.

\footnotetext{See http://www.cherryblossom.org/.}


# Methods

## Data 


### Data Collection

In this case study, we collected data on participants in the Cherry Blossom Race. We scraped the data for Men and Woman from 1999 to 2012. The data was stored under the base address in the following form, where the year is between 1999 and 2012 and page is a specific page name.

```
http://www.cherryblossom.org/results/<year>/<page>
```

The specific addresses where the data is stored are given in table 1. While the structure follows `results/<year>` consistently, the page naming for each year is not consistent. In some cases, the names for the men's and women's pages are `men` and `women`, repectively. In other cases, a code is used such as `cb99m` and `cb99f` in 1999 for `men` and `women` repectively.
\newpage
**Table 1. Web Page Pages**

| Year | Men's Pages                      | Women's Pages             |
|------|----------------------------------|---------------------------|
| 1999 | `results/1999/cb99m.html`        | `results/1999/cb99f.html` |
| 2000 | `results/2000/Cb003m.htm`        | `results/2000/Cb003f.htm` |
| 2001 | `results/2001/oof_m.html`        | `results/2001/oof_f.html` |
| 2002 | `results/2002/oofm.htm`          | `results/2002/ooff.htm`   |
| 2003 | `results/2003/CB03-M.HTM`        | `results/2003/CB03-F.HTM` |
| 2004 | `results/2004/men.htm`           | `results/2004/women.htm`  |
| 2005 | `results/2005/CB05-M.htm`        | `results/2005/CB05-F.htm` |
| 2006 | `results/2006/men.htm`           | `results/2006/women.htm`  |
| 2007 | `results/2007/men.htm`           | `results/2007/women.ht`   |
| 2008 | `results/2008/men.htm`           | `results/2008/women.htm`  |
| 2009 | `results/2009/09cucb-M.htm`      | `results/2009/09cucb-F.htm`      |
| 2010 | `results/2010/2010cucb10m-m.htm` | `results/2010/2010cucb10m-F.htm` |
| 2011 | `results/2011/2011cucb10m-m.htm` | `results/2011/2011cucb10m-F.htm` |
| 2012 | `results/2012/2012cucb10m-m.htm` | `results/2012/2012cucb10m-F.htm` |

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
```

```{r}

library(XML)
ubase = "http://www.cherryblossom.org/"
menURLs = 
  c("results/1999/cb99m.html", "results/2000/Cb003m.htm", "results/2001/oof_m.html",
    "results/2002/oofm.htm", "results/2003/CB03-M.HTM",
    "results/2004/men.htm", "results/2005/CB05-M.htm", 
    "results/2006/men.htm", "results/2007/men.htm", 
    "results/2008/men.htm", "results/2009/09cucb-M.htm",
    "results/2010/2010cucb10m-m.htm", 
    "results/2011/2011cucb10m-m.htm",
    "results/2012/2012cucb10m-m.htm")

urls = paste(ubase, menURLs, sep = "")

extractResTable =
  # takes a list of websites from the cherry blossom race
  # a list of years corresponding to the year the result is for
  # and the gender of the participant
  # Retrieve data from web site, 
  # find the preformatted text,
  # and write lines or return as a character vector.
  # returns a list of strings corrsponding to lines in the web url
  function(url = "http://www.cherryblossom.org/results/2009/09cucb-F.htm",
           year = 1999, sex = "male", file = NULL)
  {
    doc = htmlParse(url)

    if (year == 2000) {
      # Get preformatted text from 4th font element
      # The top file is ill formed so the <pre> search doesn't work.
      ff = getNodeSet(doc, "//font")
      txt = xmlValue(ff[[4]])
      els = strsplit(txt, "\r\n")[[1]]
    }
    else if (year == 2009 & sex == "male") {
      # Get preformatted text from <div class="Section1"> element
      # Each line of results is in a <pre> element
      div1 = getNodeSet(doc, "//div[@class='Section1']")
      pres = getNodeSet(div1[[1]], "//pre")
      els = sapply(pres, xmlValue)
      els = gsub("Ã‚", "", els)
    }
    else if (year == 1999) {
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\n")[[1]]   
    } 
    else {
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\r\n")[[1]]   
    } 
    if (is.null(file)) return(els)
    # Write the lines as a text file.
    writeLines(els, con = file)
  }


years = 1999:2012
menTables = mapply(extractResTable, url = urls, year = years)
names(menTables) = years
sapply(menTables, length)

save(menTables, file = "CBMenTextTables.rda")
```

The data are successfully scraped from the urls that are given and we observe that the number of participants in the Cherry Blossom race has increased steadily from 1999 to 2012. We can use the `extractResTable` function to exptract all of the results, or to specify a single set of results.

\tiny
```{r, echo = TRUE, inlcude = FALSE}
men_2009<-extractResTable(url = urls[11], year = 2009, sex = 'male')
men_2009[1:10]
```
\normalsize

We observe the formatting of the text data, such as the use of the `=` character can be used to transform the lines of text into a a matrix. We will used this pattern to identify the boundary between the headering and the body of the data. Once we defined the column names, we were free to use the text structure, such as the spacing of column names and data, to identify datapoints. We started with age, which denoted by the `"ag"` identifier. After we sucessfully used the structure of the text data to identify an index location for `"ag"` data points. We expanded the search to inlcude  the spacing of text data to identify other data points. The spacing indices were used in a funtion that compiled a matrix of data points across the entire list of tables. 

A function `findColLocs` was defined to use these space indices to locate the begin points for data throughout the extracted text data. `selectCols` is a tool that uses `findColLocs` to locate the data points for each column throughout the text for all of the race years. Our functions extracted almost all of the age data fomr the text, which aided in the identification errors within the dataset. To generalize this method, we defined a function, `extractVariables`, that combined the various processes we used to preprocess the data into a more machine readable format. 

We now have a list of matrices. The original text data are in a much more machine readable format. Our number of rows for each matrix is equal to the number of original rows, minus the original text header. To perform statistical analyses on the numeric data, we must perform a datatype transformation.

There were anomalies in the data for the year 2003. After an examination of the original data table, we found that the spacing in the year 2003 data is not the same as the other years. We adjusted our `selectCols` function to better capture the data for 2003. We also observe anomalies in the formatting of the year 2001. We introduced fixes and re-scraped the data once more to form the list of matrices called `menResMat`.

```{r}
equals_idx<- grep('^===', men_2009)
equals_idx

equals_idx2<- substr(men_2009, 1,3)
which(equals_idx2 == '===')

spacerRow<- men_2009[equals_idx]
headerRow<- men_2009[equals_idx -1]
body<- men_2009[-(1:equals_idx)] # working with 2009 body
```
```{r}
head(body)
```

```{r}
headerRow<- tolower(headerRow)
headerRow
```

```{r, inlcude = FALSE, results= 'hide'}
# looks for first match of given sequence
ageStart<- regexec('ag', headerRow, fixed = TRUE)
ageStart
```
 "        1         1/1420             1 Ridouane Harroufi           27 Morocco                               45:56     45:56#   4:36 " 
 
 "        27 " "           " "           " "       26 M" "        26 " "     23 Ken"
```{r}
age<- substr(body, start = 49, stop = 50)
head(age)
```
```{r}
summary(as.numeric(age))
```



```{r}
#gregexpr looks for all matches of a given sequence
blankLocs<- gregexpr(' ', spacerRow)
blankLocs
```
```{r}
searchLocs<- c(0,blankLocs[[1]])
searchLocs
```



```{r}
values<- mapply(substr, list(body), start = searchLocs[-length(searchLocs)] +1, stop = searchLocs[-1] -1)
length(values)
head(values)
```



```{r}
findColLocs<- function(spacerRow){
  spaceLocs<- gregexpr(' ', spacerRow)[[1]]
  rowLength<- nchar(spacerRow)
  
  if (substring(spacerRow, rowLength, rowLength) != ' ')
    return( c(0, spaceLocs, rowLength +1))
  else return(c(0,spaceLocs))
}

locs_2012<- findColLocs(spacerRow)
length(locs_2012)
locs_2012
```



```{r}
selectCols = 
function(colNames, headerRow, searchLocs) 
{
  sapply(colNames, 
         function(name, headerRow, searchLocs)
         {
           startPos = regexpr(name, headerRow)[[1]]
           if (startPos == -1) 
             return( c(NA, NA) )
    
           index = sum(startPos >= searchLocs)
           c(searchLocs[index] + 1, searchLocs[index + 1] - 1)
         },
         headerRow = headerRow, searchLocs = searchLocs )
}
```



```{r}
searchLocs = findColLocs(spacerRow)
ageLoc = selectCols("ag", headerRow, searchLocs) 
ages = mapply(substr, list(body), 
              start = ageLoc[1,], stop = ageLoc[2, ])
summary(as.numeric(ages))
```



```{r}
shortColNames = c("name", "home", "ag", "gun", "net", "time")
locCols = selectCols(shortColNames, headerRow, searchLocs)

#mapply forms a matrix after completion
Values = mapply(substr, list(body), start = locCols[1, ], 
                stop = locCols[2, ])

class(Values)

colnames(Values) = shortColNames
head(Values)
tail(Values)[ , 1:3]
```



```{r}
extractVariables = 
  function(file, varNames =c("name", "home", "ag", "gun",
                             "net", "time"))
{
       # Find the index of the row with =s
  eqIndex = grep("^===", file)
       # Extract the two key rows and the data
  spacerRow = file[eqIndex] 
  headerRow = tolower(file[ eqIndex - 1 ])
  body = file[ -(1 : eqIndex) ]
       
       # Obtain the starting and ending positions of variables
  searchLocs = findColLocs(spacerRow)
  locCols = selectCols(varNames, headerRow, searchLocs)

  Values = mapply(substr, list(body), start = locCols[1, ], 
                  stop = locCols[2, ])
  colnames(Values) = varNames
  
  invisible(Values)
}
```
```{r}

years = 1999:2012
menTables = mapply(extractResTable, url = urls, year = years)
names(menTables) = years
```



```{r}
menResMat = lapply(menTables, extractVariables)
length(menResMat)

sapply(menResMat, nrow)
```



```{r}
age = as.numeric(menResMat[['2012']][ , 'ag'])

tail(age)

age = sapply(menResMat,
             function(x) as.numeric(x[ , 'ag']))

```



```{r, include = TRUE}
boxplot(age, ylab = "Age", xlab = "Year")
```
```{r}
selectCols = function(shortColNames, headerRow, searchLocs) {
  sapply(shortColNames, function(shortName, headerRow, searchLocs){
    startPos = regexpr(shortName, headerRow)[[1]]
    if (startPos == -1) return( c(NA, NA) )
    index = sum(startPos >= searchLocs)
    c(searchLocs[index] + 1, searchLocs[index + 1])
  }, headerRow = headerRow, searchLocs = searchLocs )
}
```



```{r}
age2001 = age[["2001"]]

grep("^===", menResMat['2001'])

badAgeIndex = which(is.na(age2001)) + 5

extractVariables = 
function(file, varNames =c("name", "home", "ag", "gun",
                           "net", "time"))
{
  
  # Find the index of the row with =s
  eqIndex = grep("^===", file)
  # Extract the two key rows and the data 
  spacerRow = file[eqIndex] 
  headerRow = tolower(file[ eqIndex - 1 ])
  body = file[ -(1 : eqIndex) ]
       # Remove footnotes and blank rows
  footnotes = grep("^[[:blank:]]*(\\*|\\#)", body)
  if ( length(footnotes) > 0 ) body = body[ -footnotes ]
  blanks = grep("^[[:blank:]]*$", body)
  if (length(blanks) > 0 ) body = body[ -blanks ]
  
  
  # Obtain the starting and ending positions of variables   
  searchLocs = findColLocs(spacerRow)
  locCols = selectCols(varNames, headerRow, searchLocs)
  
  Values = mapply(substr, list(body), start = locCols[1, ], 
                  stop = locCols[2, ])
  colnames(Values) = varNames
  
  return(Values)
}

menResMat = lapply(menTables, extractVariables)
```

After these anomalies were corrected, we reformatted the datatypes. The `"ag"` data was changed to a numeric format for analysis, which revealed *more* anomalies. We observed suspiciously young ages between the years 2001 and 2003. These ages were revealed to be *erroneous* upon closer examination. These values were removed from the dataset.

To make the remaining analyses easier, we transformed the data structure from a list of matrices into a dataframe. Combining the data into a single dataframe facilitated the cleaning of the columns containing the time data for each runner. These values were stored as characters and were in an HR:MIN:SEC format. We can separate the values and convert them all into a standard time format, minutes. We defined a function that converts the time into a minute format. 

The end result was a dataframe called menDF. With this process complete, we simply re-used the functions on the women's data. 

```{r}
age<- sapply(menResMat, function(x) as.numeric(x[, 'ag']))
```

```{r}
sapply(age, function(x) sum(is.na(x)))
```



```{r}
boxplot(age, ylab = "Age", xlab = "Year")
```



```{r}
young<- menResMat[['2001']][,'ag'] < 10
menResMat[['2001']]<- menResMat[['2001']][-c(young),]
y2002<- menResMat[['2002']][,'ag'] < 10
y2003<- menResMat[['2003']][,'ag'] < 10
menResMat[['2002']]<- menResMat[['2002']][-c(y2002),]
menResMat[['2003']]<- menResMat[['2003']][-c(y2003),]
y2002<- menResMat[['2002']][,'ag'] < 10
y2003<- menResMat[['2003']][,'ag'] < 10
```



```{r}
menResDF = lapply(menResMat, data.frame)
```
```{r}
col_1999 = rep(1999, nrow(menResDF$`1999`))

col_2000 = rep(2000, nrow(menResDF$`2000`))

col_2001 = rep(2001, nrow(menResDF$`2001`))

col_2002 = rep(2002, nrow(menResDF$`2002`))

col_2003 = rep(2003, nrow(menResDF$`2003`))

col_2004 = rep(2004, nrow(menResDF$`2004`))

col_2005 = rep(2005, nrow(menResDF$`2005`))

col_2006 = rep(2006, nrow(menResDF$`2006`))

col_2007 = rep(2007, nrow(menResDF$`2007`))

col_2008 = rep(2008, nrow(menResDF$`2008`))

col_2009 = rep(2009, nrow(menResDF$`2009`))

col_2010 = rep(2010, nrow(menResDF$`2010`))

col_2011 = rep(2011, nrow(menResDF$`2011`))

col_2012 = rep(2012, nrow(menResDF$`2012`))

cols = c(col_1999, col_2000, col_2001, col_2002, col_2003, col_2004, col_2005, col_2006, col_2007, col_2008, col_2009, col_2010, col_2011, col_2012)
```

```{r}
menResFinal = data.frame()
for (i in 1:length(names(menResDF))) {
  
  df<- menResDF[[i]]
  menResFinal = rbind(menResFinal, df)
}
menResFinal$Date<- cols
```



```{r}
menResFinal$ag = as.numeric(menResFinal$ag)
sum(is.na(menResFinal$ag))
```



```{r, include = FALSE}
times = menResFinal$time
timePieces = strsplit(as.character(times), ":")

tail(timePieces)

timePieces = sapply(timePieces, as.numeric)
head(timePieces)
```



```{r}
runTime = sapply(timePieces, 
                 function(x) {
                   if (length(x) == 2) x[1] + x[2]/60
                   else 60*x[1] + x[2] + x[3]/60
                 })

summary(runTime)
```
```{r}
convertTime = function(time) {
  timePieces = strsplit(time, ":")
  timePieces = sapply(timePieces, as.numeric)
  sapply(timePieces, function(x) {
                      if (length(x) == 2) x[1] + x[2]/60
                      else 60*x[1] + x[2] + x[3]/60
                      })
}
```



```{r, include = FALSE}
createDF = function(Res, year, sex) 
{
  # Determine which time to use
  if ( !is.na(Res[1, 'net']) ) useTime = Res[ , 'net']
  else if ( !is.na(Res[1, 'gun']) ) useTime = Res[ , 'gun']
  else useTime = Res[ , 'time']
  
  # Remove # and * and blanks from time
  useTime = gsub("[#\\*[:blank:]]", "", useTime)
  runTime = convertTime(useTime[ useTime != "" ])
  
  # Drop rows with no time
  Res = Res[ useTime != "", ]
  
  Results = data.frame(year = rep(year, nrow(Res)),
                       sex = rep(sex, nrow(Res)),
                       name = Res[ , 'name'], home = Res[ , 'home'],
                       age = as.numeric(Res[, 'ag']), 
                       runTime = runTime,
                       stringsAsFactors = FALSE)
  invisible(Results)
}

menDF = mapply(createDF, menResMat, year = 1999:2012,
               sex = rep("M", 14), SIMPLIFY = FALSE)
```


```{r}
sapply(menDF, function(x) sum(is.na(x$runTime)))

separatorIdx = grep("^===", menTables[["2006"]])
separatorRow = menTables[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ", 
                      substring(separatorRow, 65, nchar(separatorRow)), 
                      sep = "")
menTables[['2006']][separatorIdx] = separatorRowX

menResMat = sapply(menTables, extractVariables)
menDF = mapply(createDF, menResMat, year = 1999:2012,
               sex = rep("M", 14), SIMPLIFY = FALSE)
```



```{r}
womenURLs = 
  c("results/1999/cb99f.html", "results/2000/Cb003f.htm", "results/2001/oof_f.html",
    "results/2002/ooff.htm", "results/2003/CB03-F.HTM",
    "results/2004/women.htm", "results/2005/CB05-F.htm", 
    "results/2006/women.htm", "results/2007/women.htm", 
    "results/2008/women.htm", "results/2009/09cucb-F.htm",
    "results/2010/2010cucb10m-F.htm", 
    "results/2011/2011cucb10m-F.htm",
    "results/2012/2012cucb10m-F.htm")

years = 1999:2012
urls = paste(ubase, womenURLs, sep = "")
womenTables = mapply(extractResTable, url = urls, year = years, sex='female')
names(womenTables) = years
sapply(womenTables, length)
```


```{r, inlcude = FALSE}
separatorIdx = grep("^===", womenTables[["2006"]])
separatorRow = womenTables[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ",
                      substring(separatorRow, 65, nchar(separatorRow)),
                      sep = "")
womenTables[['2006']][separatorIdx] = separatorRowX

womenTables[['2001']][2:3] = womenTables[['2002']][2:3]

womenResMat = sapply(womenTables, extractVariables)
womenDF = mapply(createDF, womenResMat, year = 1999:2012,
               sex = rep("W", 14), SIMPLIFY = FALSE)
```



```{r}
sapply(womenDF, function(x) sum(is.na(x$age)))
```



```{r}
sapply(womenDF, function(x) sum(is.na(x$runTime)))
```



```{r}
menDF_complete = na.omit(menDF)
womenDF_complete = na.omit(womenDF)
```



```{r}
cherryblossom = data.frame()
for (i in 1:14) {
  
  df<- menDF_complete[[i]]
  cherryblossom = rbind(cherryblossom, df)
}
head(cherryblossom)
```

```{r}
for (i in 1:14) {
  
  df<- womenDF_complete[[i]]
  cherryblossom = rbind(cherryblossom, df)
}
tail(cherryblossom)
```
```{r}
sum(is.na(cherryblossom))
```

Our dataset is complete, clean, and ready for further analysis.

```{r}
cherryblossom = na.omit(cherryblossom)
sum(is.na(cherryblossom))
```
```{r, include= TRUE}
head(cherryblossom)
```


# Conclusion
Some of the fastest average runners in the world participating in the race come from Tanzania, Morocco, and Colombia while the nation represented by the slowest average runner is Ireland.

```{r}
library(pacman)
p_load(rnaturalearth,countrycode,tidyverse,ggplot2,ggthemes,viridis,rgeos,usmap, sqldf, gdata, maps)

cherryblossom[gdata::trim(cherryblossom$name)=="Matthew Rogers",]$home = "Arlington VA"
cherryblossom[gdata::trim(cherryblossom$name)=="Adri Jayaratne",]$home = "Washington DC"
cherryblossom[gdata::trim(cherryblossom$name)=="Marla Hallacy",]$home = "Washington DC"
cherryblossom[gdata::trim(cherryblossom$name)=="Eleanor Rathbone",]$home = "Washington DC"
cherryblossom[gdata::trim(cherryblossom$name)=="Emily Naden",]$home = "Washington DC"
cherryblossom[gdata::trim(cherryblossom$name)=="Grace L Chen",]$home = "Washington DC"
cherryblossom[gdata::trim(cherryblossom$name)=="Stephanie Rogers",]$home = "Aldie VA"
cherryblossom[gdata::trim(cherryblossom$name)=="Sarah Garner",]$home = "	Arlington VA"
cherryblossom[gdata::trim(cherryblossom$name)=="Maria Solomon",]$home = "Arlington VA"
cherryblossom[gdata::trim(cherryblossom$name)=="Amy Iacopi",]$home = "San Francisco CA"
cherryblossom[gdata::trim(cherryblossom$name)=="Sarah Watkins",]$home = "Washington DC"
cherryblossom[gdata::trim(cherryblossom$name)=="Alissa Havens",]$home = "Washington DC"

cherryblossomX = cherryblossom

cherryblossomX[gdata::trim(cherryblossomX$home)=="AUS",]$home = "Australia"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Bri",]$home = "United Kingdom of Great Britain and Northern Ireland"
cherryblossomX[gdata::trim(cherryblossomX$home)=="CAN",]$home = "Canada"
cherryblossomX[gdata::trim(cherryblossomX$home)=="COL",]$home = "Colombia"
cherryblossomX[gdata::trim(cherryblossomX$home)=="CZE",]$home = "Czech Republic"
cherryblossomX[gdata::trim(cherryblossomX$home)=="ETH",]$home = "Ethiopia"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Eth",]$home = "Ethiopia"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Fra",]$home = "France"
cherryblossomX[gdata::trim(cherryblossomX$home)=="GER",]$home = "Germany"
cherryblossomX[gdata::trim(cherryblossomX$home)=="IRE",]$home = "Ireland"
cherryblossomX[gdata::trim(cherryblossomX$home)=="JAP",]$home = "Japan"
cherryblossomX[gdata::trim(cherryblossomX$home)=="KEN",]$home = "Kenya"
cherryblossomX[gdata::trim(cherryblossomX$home)=="KOR",]$home = "Republic of Korea"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Ken",]$home = "Kenya"
cherryblossomX[gdata::trim(cherryblossomX$home)=="LIT",]$home = "Lithuania"
cherryblossomX[gdata::trim(cherryblossomX$home)=="MEX",]$home = "Mexico"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Mex",]$home = "Mexico"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Ny",]$home = "United States"
cherryblossomX[gdata::trim(cherryblossomX$home)=="MD",]$home = "United States"
cherryblossomX[gdata::trim(cherryblossomX$home)=="PER",]$home = "Peru"
cherryblossomX[gdata::trim(cherryblossomX$home)=="POL",]$home = "Poland"
cherryblossomX[gdata::trim(cherryblossomX$home)=="RSA",]$home = "South Africa"
cherryblossomX[gdata::trim(cherryblossomX$home)=="ROM",]$home = "Romania"
cherryblossomX[gdata::trim(cherryblossomX$home)=="RUS",]$home = "Russia"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Rom",]$home = "Romania"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Rus",]$home = "Russia"
cherryblossomX[gdata::trim(cherryblossomX$home)=="SCO",]$home = "United Kingdom of Great Britain and Northern Ireland"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Us",]$home = "United States"
cherryblossomX[gdata::trim(cherryblossomX$home)=="Usa",]$home = "United States"

dropVars <- c("", "Lee","M")
cherryblossomX <- cherryblossomX[!(gdata::trim(cherryblossomX$home) %in% dropVars ),]

for(i in 1:length(cherryblossomX$home)){
  if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-1, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% c('AL','AK','AZ','AR','CA','CO','CT','DE','DC','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY','VI')){
    cherryblossomX$home[i] <- 'United States'
  }
  if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-2, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% c('afb','AFB')){
    cherryblossomX$home[i] <- 'United States'
  }
  if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-2, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% c('ONT')){
    cherryblossomX$home[i] <- 'Canada'
  }
  if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-1, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% c('UK','LE')){
    cherryblossomX$home[i] <- 'United Kingdom of Great Britain and Northern Ireland'
  }
  if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-1, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% c('CN','ON','NO','SA','BC')){ # Ontario, Nova Scotia, Seskatchewan, British Colombia
    cherryblossomX$home[i] <- 'Canada'
  }
  if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-1, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% 'PR'){
    cherryblossomX$home[i] <- 'Puerto Rico'
  }
    if(substr( trim(cherryblossomX$home[i]), nchar(gdata::trim(cherryblossomX$home[i]))-1, nchar(gdata::trim(cherryblossomX$home[i])) ) %in% 'GE'){
    cherryblossomX$home[i] <- 'Germany'
    }
  if(trim(cherryblossomX$home[i]) %in% 'Rep Of S.africa'){
    cherryblossomX$home[i] <- 'South Africa'
  }
  if(trim(cherryblossomX$home[i]) %in% 'Dominican Republi'){
    cherryblossomX$home[i] <- 'Dominican Republic'
  }
  if(trim(cherryblossomX$home[i]) %in% 'Scotland'){
    cherryblossomX$home[i] <- 'United Kingdom of Great Britain and Northern Ireland'
  }
  if(trim(cherryblossomX$home[i]) %in% 'NewZealand'){
    cherryblossomX$home[i] <- 'New Zealand'
  }
  if(trim(cherryblossomX$home[i]) %in% 'Russia'){
    cherryblossomX$home[i] <- 'Russian Federation'
  }
  if(trim(cherryblossomX$home[i]) %in% 'Tanzania'){
    cherryblossomX$home[i] <- 'Tanzania, United Republic of'
  }
  else{
    if(!gdata::trim(cherryblossomX$home[i]) %in% c('Australia','Bolivia, Plurinational State of','Brazil','United Kingdom of Great Britain and Northern Ireland','Canada','Colombia','CzechRepublic','DominicanRepubli','DominicanRepublic','Dominican Republic','Czech Republic','South Africa','Puerto Rico','Ethiopia','France','Germany','Guatemala','Ireland','Japan','Kenya','Republic of Korea','Lithuania','Malta','Mexico','Morocco','NewZealand','New Zealand','Peru','Poland','PuertoRico','RepOfS.africa','Romania','Russia','Russian Federation','SouthAfrica','Trinidad and Tobago','Ukraine','UnitedKingdom','Uruguay','Tanzania, United Republic of','Slovenia')){
      cherryblossomX$home[i] <- 'United States'
    }
  }
}
```
```{r, include = T}
cherryblossomX$home <- gdata::trim(cherryblossomX$home)


# names(cherryblossomX)
# sqldf("select home, avg(runTime) from cherryblossomX group by home order by avg(runTime) asc")

dat <- iso3166

cherryblossom_country_runtimes <- sqldf("select d.a3, d.mapname, avg(x.runTime) as runTime from cherryblossomX x join dat d on x.home = d.ISOname group by d.a3, d.mapname")

map <- ne_countries(scale = "medium", returnclass = "sf")
runners_map <- merge(map, cherryblossom_country_runtimes, by.x = "adm0_a3", by.y = "a3", all = TRUE)

assoc_graph <- ggplot(data = runners_map) +
  geom_sf(aes(fill = runTime), 
          position = "identity") + 
  labs(fill='Average\nCompletion Time')  +
  scale_fill_viridis_c(option = "viridis") +
   ggtitle('Average Race Completion Time, by Country')

assoc_graph + theme_map()

```


\appendix


# Code

```
The code is cooool
```

