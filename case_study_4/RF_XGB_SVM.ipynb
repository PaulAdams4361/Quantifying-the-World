{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Stuart Miller, Paul Adams, and Justin Howard\n",
    "\n",
    "# **Introduction**\n",
    "\n",
    "Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Methods**\n",
    "\n",
    "## **Data**\n",
    "\n",
    "Banking data, we don't know anything about the data!\n",
    "\n",
    "## **Models**\n",
    "\n",
    "Description of the models used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**\n",
    "\n",
    "Random Forest stuff!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost**\n",
    "\n",
    "[XGB](https://towardsdatascience.com/from-zero-to-hero-in-xgboost-tuning-e48b59bfaf58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**\n",
    "\n",
    "Hyperparameters were selected with a randomized search with 5-fold internal cross-validation.\n",
    "We used a randomized search rather than an exhaustive search (sometimes called grid search) \n",
    " because randomized searches have been shown to achieve similar results,\n",
    " but with significantly lower run times than exhaustive search.\n",
    "Unlike in an exhaustive search where all possible combinations of tuning parameters are validated,\n",
    " in a randomized search a number of search iterations are specified and\n",
    " a random set of parameters are validated on each iteration\n",
    "In this application of randomized search, 5-fold cross-validation is performed at each iteration.\n",
    "The best parameters from the search are selected based on the mean cross-validated log loss.\n",
    "\n",
    "We ran the random forest and XGBoost hyperparameter searches for 100 iterations.\n",
    "We only ran the SVM hyperparameter search for 10 iterations due to the high run time of fitting the model.\n",
    "The tuning parameters for each model used in the case study are shown in tables X-Z.\n",
    "\n",
    "\n",
    "**Table X. Random Forest Tuning Parameters**\n",
    "\n",
    "| Parameter           | Search Range                    |\n",
    "|---------------------|:-------------------------------:|\n",
    "| `n_estimators`      | 10:150                          |\n",
    "| `criterion`         | One of `'gini', 'entropy'`      |\n",
    "| `max_depth`         | 10:100                          | \n",
    "| `min_samples_split` | 2:100                           |\n",
    "| `min_samples_leaf`  | 2:100                           |\n",
    "| `max_features`      | One of `'auto', 'sqrt', 'log2'` |\n",
    "\n",
    "**Table Y. XGBoost Tuning Parameters**\n",
    "\n",
    "| Parameter           | Search Range                    |\n",
    "|---------------------|:-------------------------------:|\n",
    "| `A`      |                        |\n",
    "| `B`         | One of       |\n",
    "\n",
    "\n",
    "**Table Z. SVM Tuning Parameters**\n",
    "\n",
    "| Parameter | Search Range                                |\n",
    "|-----------|:-------------------------------------------:|\n",
    "| `C`       | 0.001:10\\*                                  |\n",
    "| `kernel`  | One of `'linear', 'poly', 'rbf', 'sigmoid'` |\n",
    "| `gamma`   | One of `'scale', 'auto'`                    | \n",
    "\n",
    "\\*value distibution on a log scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results**\n",
    "\n",
    "* Hyperparameter tuning tables\n",
    "* Validation results for RF, XGB, SVM <- let's do a test set here\n",
    "* Scaling times for SVM (1k, 2k, 5k, 10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**\n",
    "\n",
    "the conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    accuracy_score,\n",
    "    make_scorer)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    RandomizedSearchCV, \n",
    "    cross_validate)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_loss_scorer = make_scorer(log_loss, greater_is_better=False)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get the data\n",
    "data = pd.read_csv('./data/case_8.csv')\n",
    "# put the target in another variable\n",
    "target = data.target\n",
    "# drop off ID and target\n",
    "data = data.drop(['ID', 'target'], axis=1)\n",
    "# get train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    target,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stuart/anaconda3/envs/tf2/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/stuart/anaconda3/envs/tf2/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "obj_columns = list(data.select_dtypes(include='object'))\n",
    "obj_col_encoders = {col: LabelEncoder() for col in obj_columns}\n",
    "\n",
    "for col in obj_col_encoders.keys():\n",
    "    obj_col_encoders[col].fit(data[col])\n",
    "    \n",
    "for col in obj_col_encoders.keys():\n",
    "    X_train[col] = obj_col_encoders[col].transform(X_train[col])\n",
    "    X_test[col] = obj_col_encoders[col].transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized CV search done. 10 iterations took 00::25::42\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=random_state)\n",
    "rf_params = {\n",
    "    'n_estimators': np.linspace(10, 150, dtype='int'),\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth': np.linspace(10, 100, dtype='int'),\n",
    "    'min_samples_split': np.linspace(2, 100, 50, dtype='int'),\n",
    "    'min_samples_leaf': np.linspace(2, 100, 50, dtype='int'),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "search_iters = 100\n",
    "\n",
    "rf_RSCV_start_time = time.time()\n",
    "# setup search\n",
    "rf_RSCV = RandomizedSearchCV(rf_clf, rf_params, scoring=log_loss_scorer,\n",
    "                                 n_iter=search_iters, random_state=random_state)\n",
    "# seach\n",
    "rf_RSCV.fit(X_train, y_train)\n",
    "\n",
    "rf_RSCV_end_time = time.time()\n",
    "duration = rf_RSCV_end_time-rf_RSCV_start_time\n",
    "\n",
    "print(f'Randomized CV search done. {search_iters} iterations took \\\n",
    "{int(duration // 3600):02d}::{int((duration % 3600)//60):02d}::{int((duration % 3600) % 60):02d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini',\n",
      " 'max_depth': 70,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 68,\n",
      " 'n_estimators': 44}\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters chosen by CV\n",
    "pprint.pprint(rf_RSCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get CV results with best parameters\n",
    "rf_clf.set_params(**rf_RSCV.best_params_)\n",
    "rf_cv = cross_validate(rf_clf, X_train, y_train, \n",
    "                       scoring={\n",
    "                           'log_loss':log_loss_scorer,\n",
    "                           'accuracy':accuracy_scorer\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Validation Performance\n",
      "Mean Log Loss\t7.735369922195444\n",
      "Mean Accuracy\t0.7760428226385534\n"
     ]
    }
   ],
   "source": [
    "print('RF 5-fold Validation Performance')\n",
    "# note test_log_loss is negated due to how scorers work \n",
    "# in parameter searches in sklearn\n",
    "print('Mean Log Loss\\t{}'.format(np.mean(-rf_cv['test_log_loss'])))\n",
    "print('Mean Accuracy\\t{}'.format(np.mean(rf_cv['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Test Set Performance\n",
      "Test Log Loss\t7.651903959831961\n",
      "Test Accuracy\t0.7784551768011451\n"
     ]
    }
   ],
   "source": [
    "# get performance on test set\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print('RF Test Set Performance')\n",
    "print('Test Log Loss\\t{}'.format(log_loss(rf_y_test_pred, y_test)))\n",
    "print('Test Accuracy\\t{}'.format(accuracy_score(rf_y_test_pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
